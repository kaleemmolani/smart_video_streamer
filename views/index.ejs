<!DOCTYPE html>
<html lang="en">


  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>HTTP Video Stream</title>
    
  </head>
  <body>
    
    <video id="videoPlayer" width="850" controls autoplay>
      <source src="/video" type="video/mp4" />
    </video>
    <video id="video" width="720" height="560" autoplay muted style='visibility: hidden'></video>
  </body>

  <script>
    const video = document.getElementById('video');
    const streamPLayer = document.getElementById('videoPlayer');
    
    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('/models/tiny_face_detector_model-weights_manifest.json')
    ],
    ).then(startVideo)
    
    async function startVideo() {
      navigator.getUserMedia(
        { video: {} },
        stream => video.srcObject = stream,
        err => console.error(err)
      )
      
    }

    video.addEventListener('play', () => {
      const canvas = faceapi.createCanvasFromMedia(video)
      //document.body.append(canvas)
      const displaySize = { width: video.width, height: video.height }
      faceapi.matchDimensions(canvas, displaySize)
      setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
        const resizedDetections = faceapi.resizeResults(detections, displaySize)
        
        if(resizedDetections.length>0){
          console.log("koi to h ");
          streamPLayer.play();
          
        }
        else if(resizedDetections.length<1){
          streamPLayer.pause();
          console.log('koi nhi h');
        }
        console.log(resizedDetections.length)
      }, 100)
    })
  </script>
</html>